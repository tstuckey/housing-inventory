{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T18:13:16.786564Z",
     "end_time": "2023-04-16T18:13:18.229867Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Inventory - Model\n",
    "\n",
    "Let's get the data staged in our dataframe, again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def create_connection(db_file: str) -> list:\n",
    "    \"\"\"\n",
    "    Create a database connection to the SQLite database specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cur = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cur = conn.cursor()\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    "    return [conn, cur]\n",
    "\n",
    "\n",
    "def close_connection(db_conn: sqlite3.Connection) -> None:\n",
    "    return db_conn.close()\n",
    "\n",
    "\n",
    "db_file = 'housing_inventory.db'\n",
    "db_con, db_cur = create_connection(db_file)\n",
    "\n",
    "query = \"\"\"\n",
    "WITH mortgage_monthly(year_month, mortgage_rate) AS (\n",
    "    SELECT year_month, avg(mortgage_rate) from mortgage_rates\n",
    "    group by year_month\n",
    ")\n",
    "SELECT  hi.total_listing_count as 'housing_inventory', bp.total_units as 'housing_permits',\n",
    "        mm.mortgage_rate, pr.prime_rate, rc.credit, hi.cbsa_code, mm.year_month\n",
    "FROM housing_inventory as hi\n",
    "INNER JOIN building_permits bp\n",
    "    on hi.year_month = bp.year_month and hi.cbsa_code = bp.cbsa_code\n",
    "INNER JOIN mortgage_monthly mm\n",
    "    on hi.year_month = mm.year_month\n",
    "INNER JOIN prime_rates pr\n",
    "    on hi.year_month = pr.year_month\n",
    "INNER JOIN revolving_credit rc\n",
    "    on hi.year_month = rc.year_month\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(sql=query,con=db_con)\n",
    "close_connection(db_con)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T18:13:16.831962Z",
     "end_time": "2023-04-16T18:13:18.386425Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build the Casual Loop Diagram\n",
    "\n",
    "Based on our EDA correlations, let's recap and stage a CLD table lookup to facilitate our analysis:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\begin{array}{ccc}\n",
    "\\text{Variable Name} & \\text{Expected CLD sign to Housing Inventory} & \\text{comment}\\\\\n",
    "\\hline\n",
    "\\text{housing permits} & \\text{positive} & \\text{More building permits mean more higher inventory} \\\\\n",
    "\\text{mortgage rate} & \\text{positive} & \\text{Higher mortgage rates should yield higher inventory} \\\\\n",
    "\\text{credit} & \\text{negative} & \\text{Higher credit showed a slight decrease in inventory} \\\\\n",
    "\\text{prime rate} & \\text{positive} & \\text{Slight increase in prime rate increased inventory} \\\\\n",
    "\\text{cbsa code} & \\text{N/A} & \\text{categorical variable for car origin}\\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detailed discussions of the signs of each of these is available in [Housing Inventory - Explore](Housing%20Inventory%20-%20Explore.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Null-Model\n",
    "\n",
    "Recapping the single variable EDA, our null model for the housing inventory looks like the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T18:13:18.368755Z",
     "end_time": "2023-04-16T18:13:18.402867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    296544.000000\nmean       3634.159599\nstd        8178.430136\nmin         118.000000\n25%         657.000000\n50%        1318.500000\n75%        2963.000000\nmax      108702.000000\nName: housing_inventory, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['housing_inventory'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the empirical normal distribution, with a 95% error bounds, we would expect 95% of our values to fall in the range $\\mu \\pm 1.96 \\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T18:13:18.399153Z",
     "end_time": "2023-04-16T18:13:18.449705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For our null model we expect 95% of the values to fall within the range -12395.54 <= 3634.16 <= 10757.11\n"
     ]
    }
   ],
   "source": [
    "null_mu = np.mean(df['housing_inventory'])\n",
    "null_sd = np.std(df['housing_inventory'])\n",
    "print('For our null model we expect 95% of the values to fall within the range {a} <= {b} <= {c}'.format(a = round(null_mu - 1.96 * null_sd, 2), b = round(null_mu,2), c = round(null_mu + 1.96 * null_mu,2) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we cannot have negative housing inventory, so a more pragmatic null model with 95% error bounds would be 0 <= 3634.16<= 10757.11\n",
    "And to summarize for our null model:\n",
    "- expected value: 3634.16\n",
    "- error: 81878.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Model Development\n",
    "\n",
    "Now let's start building our linear model. First let's do some setup for categorical variable encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T18:13:18.415713Z",
     "end_time": "2023-04-16T18:13:19.256035Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['cbsa_code'], prefix='cbsa_encoded')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, although is a repeat of our EDA, let's get the correlations en-masse for our numeric variables (thus, excluding the hundreds of cbsa regions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mhp\u001B[49m\u001B[38;5;241m.\u001B[39mget_correlations_en_masse(data\u001B[38;5;241m=\u001B[39mdf, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhousing_inventory\u001B[39m\u001B[38;5;124m'\u001B[39m, xs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhousing_permits\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmortgage_rate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprime_rate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcredit\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "hp.get_correlations_en_masse(data=df, y = 'housing_inventory', xs = ['housing_permits', 'mortgage_rate', 'prime_rate', 'credit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is just portion repetition of the EDA steps. For more detailed discussion, please see [Housing Iventory - Explore](Housing%20Inventory%20-%20Explore.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1a Linear Model Development\n",
    "\n",
    "Let's first try with all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbsa_mask = ['cbsa' in x for x in df.columns]\n",
    "cbsa_cols = [b for a,b in zip(cbsa_mask, df.columns) if a]\n",
    "\n",
    "# cut-out the org cbsa_code and the last one\n",
    "cbsa_cols = cbsa_cols[1:-1]\n",
    "cbsa_cols = ' + '.join(cbsa_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = 'housing_inventory ~ housing_permits + mortgage_rate + credit+ prime_rate +'+cbsa_cols\n",
    "result1 = hp.bootstrap_linear_regression(formula=model1, data = df)\n",
    "hp.describe_bootstrap_lr(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mean error was just 1488.35, a substantial improvement from 8178.64 in our null model. Moreover, the $R^2$ is already an astoundingly good 97%! Only downside... this is a _very_ precise model that functionally requires the population of very sparse matrix.  Let's take a different route where we instead generalize without the `cbsa code` in the model generation process at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1b Linear Model Development\n",
    "\n",
    "Let's try again without the `cbsa codes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.filter(regex='cbsa_encoded*').columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = 'housing_inventory ~ housing_permits + mortgage_rate + credit + prime_rate'\n",
    "result2 = hp.bootstrap_linear_regression(formula=model2, data = df)\n",
    "hp.describe_bootstrap_lr(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, our mean error isn't a good as the first model, 5194.67 vs. 1488.35, but it is still far better than our null model's error of 81878.64. Our coefficient of determination, $R^2$ took a big hit, though, at 0.60 vs. 0.97. This model is far easier to use, though.  This said, let's work to improve that $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coefficient Analysis**\n",
    "\n",
    "Given that our CLD is focused just on `housing permits`, `mortgage rates`, `credit`, and `prime rate`, let's focus on those first. Let's bring the Gelman table up for reference:\n",
    "![Gelman table](images/Rule%20of%20Thumb%20examining%20coefficients%20and%20credible%20bounds.jpeg)\n",
    "\n",
    "For `housing permits` was expected to be positive, and it had strong evidence supporting this. We will retain `housing permits` accordingly. `mortgage rate` as well, was expected to be positive, and it was positive with strong supporting evidence. Let's retain in as well. `credit` was expected to be negative and was negative; however, the evidence was very weak and it did include zero. Following Gelman's advice, though; let's retain the `credit` variable. Lastly, for `prime_rate`, we expected it to be positive, and it was positive; however, the data was mixed in the support for this. Following guidance, though, let's retain `prime_rate` as well.\n",
    "\n",
    "\n",
    "**Residual Analysis**\n",
    "\n",
    "Given the CLD analysis indicated we should retain all the variables, let's look at the residuals to see if any trends present that we can leverage to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals2 = hp.plot_residuals(data = df, result = result2, variables= ['housing_permits', 'mortgage_rate', 'credit', 'prime_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`housing_permits` doesn't look so great. While it is symmetric, the distinctive cone of heteroscedasticity is present. This means that there is a substantial variance for `housing_permits` with respect to the housing inventory. A more in-depth approach like _weighted-least squares_ might be an appropriate remedy for future analyis, but let's leave it as-is for this analysis.[1] `mortgage_rate`, `credit`, and `prime_rate` all have similar shapes and some tendencies toward symmetry. We say \"tendencies toward symmetry\" as all three variables have higher positive residual maximums but have denser negative residuals across their respective domains. At a minimum, let's try adding some interaction terms to see if that might capture correlations. From domain knowledge, we clearly anticipate a strong correlation between the prime-rate and the mortgage rate, but the residual plots indicate we should also include `credit` when we look at variable interactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1c Linear Model Development\n",
    "\n",
    "Let's try adding a single interaction term between the `mortgage_rate` and `prime_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = 'housing_inventory ~ housing_permits + mortgage_rate + credit + prime_rate + mortgage_rate:prime_rate'\n",
    "result3 = hp.bootstrap_linear_regression(formula=model3, data = df)\n",
    "hp.describe_bootstrap_lr(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the interaction term between `mortgage_rate` and `prime_rate` lowered the error minutely, from 5194 from 5190, but the $R^2$ stayed the same at 0.60. Let's try adding in seperate interaction terms for `mortgage_rate` and `credit`, `prime_rate` and `credit`, and one for all three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1d Linear Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = 'housing_inventory ~ housing_permits + mortgage_rate + credit + prime_rate + mortgage_rate:prime_rate + mortgage_rate:credit + prime_rate:credit + mortgage_rate:prime_rate:credit'\n",
    "result4 = hp.bootstrap_linear_regression(formula=model4, data = df)\n",
    "hp.describe_bootstrap_lr(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our error improved again, the $R^2$ is still at 0.60. Let's double-check our residuals again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals4 = hp.plot_residuals(data = df, result = result4, variables= ['housing_permits', 'mortgage_rate', 'credit', 'prime_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general shapes of all four residual plots is very similar as before. Although it's not theoretically ideal (WLS is a better course of action), let's try a transform on `housing_permits` to see we can improve the $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1e Linear Model Development\n",
    "\n",
    "Let's try taking the natural log of the permits to see how that affects everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lg_housing_permits'] = np.log(df['housing_permits'])\n",
    "model5 = 'housing_inventory ~ lg_housing_permits + mortgage_rate + credit + prime_rate + mortgage_rate:prime_rate + mortgage_rate:credit + prime_rate:credit + mortgage_rate:prime_rate:credit'\n",
    "result5 = hp.bootstrap_linear_regression(formula=model5, data = df)\n",
    "hp.describe_bootstrap_lr(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this was not the direction to go at all! Our error went up dramatically, and our $R^2$ plummeted.\n",
    "\n",
    "Let's revert and try one last course of action focused on transforming credit since it has had such a low influence (looking at its coefficients) and since it is an innately country aggregate value per month that might require some transforms to better reflect its true influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1f Linear Model Development\n",
    "\n",
    "Perhaps transforming the aggregate credit value will improve our model. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lg10_credit']= np.log10(df['credit'])\n",
    "model6 = 'housing_inventory ~ housing_permits + mortgage_rate + lg10_credit + prime_rate + mortgage_rate:prime_rate + mortgage_rate:lg10_credit + prime_rate:lg10_credit + mortgage_rate:prime_rate:lg10_credit'\n",
    "result6 = hp.bootstrap_linear_regression(formula=model6, data = df)\n",
    "hp.describe_bootstrap_lr(result5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this did not improve our model, the error went up again, but at least the $R^2$ remained consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2a Describe the final model\n",
    "\n",
    "Let's use model4,\n",
    "```\n",
    "'housing_inventory ~ housing_permits + mortgage_rate + credit + prime_rate + mortgage_rate:prime_rate + mortgage_rate:credit + prime_rate:credit + mortgage_rate:prime_rate:credit'\n",
    "```\n",
    "As our best model for this analysis. Let's rerun model4 so we have the information handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.describe_bootstrap_lr(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our final model that abstracts away from specific `cbsa_code`s,:\n",
    "$$\\hat{y}=79342.25 + 10.37 \\beta_1 - 29330.08 \\beta_2 - 0.11 \\beta_3 + 17737.31 \\beta_4 - 2339.83 \\beta_5 + 0.04 \\beta_6  - 0.01 \\beta_7$$\n",
    "\n",
    "- $\\beta_0$ = the intercept of 79,342 represents the constant estimate of the housing inventory if all other factors are zero.\n",
    "- $\\beta_1$ = the coefficient of 10.37 means the housing inventory increases 10.37 for every permit that is issued; this is a little counterintuitive as clearly a single permit strictly has a 1-1 relationship with actual housing inventory. However, the issuance of a permit is a leading indicator for future housing inventory numbers. This coefficient effectively compresses the time effect into a single contemporary estimate. Restated from this data set, we can infer than each permit issued is a very strong indicator of future housing inventory\n",
    "- $\\beta_2$ = the coefficient of -29,330 means that for every point of increase in the mortgage rate interest the housing inventory decreases by 29,330 units; this makes sense a full point of mortgage interest on a $\\$$500,000$ home loan would result in an additional $\\$$417$ per month of mortgage interest payment. Accordingly, people would be less inclined to buy. Initially this might produce an actual increase in inventory, but over time that mortgage point increase would likely cause the reduction as builders would stop building, and sellers, not finding buyers, would either take their homes off the market or sell at a loss.\n",
    "- $\\beta_3$ = the coefficient of -0.11 means that for every increase in every million dollars of revolving credit (the unit used in the revolving credit data), the housing inventory would decrease by 0.11 house.\n",
    "- $\\beta_4$ = the coefficient of 17,737 means that for every increase in the prime rae percentage, the number of housing inventory increases by 17,737. This is counter-intuitive as the prime-rate is often erroneously directly tied to the mortgage rate, and this dataset shows that is not the case.\n",
    "- $\\beta_5$ = the coefficient of interaction term between the mortgage rate and the prime rate is -2,339; this means for every unit increase the product of the two rates, the housing inventory reduces by 2,339 units.\n",
    "- $\\beta_6$ = the coefficient of the interaction term between the mortgage rate and the millions of revolving credit is 0.04; this means for every unit increase in product of the mortgage rate and million dollars of revolving credit, the housing inventory increases by 0.04.\n",
    "- $\\beta_7$ = the coefficient of the interaction term between the prime rate and the millions of revolving credit is -0.01; this means for every unit of the increase in the product of the prime rate and millions of revolving credit, the available housing reduces by 0.01\n",
    "- $\\beta_8$ =  the coefficient of the interaction term between the mortgage_rate, prime_rate, and millions of revolving credit is 0; this means that there is no affect when these three and looked at as a composite fact; accordingly it is left out of the final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2b Describe the final model\n",
    "\n",
    "Let's use cross-validation to check the bounds on the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = hp.cross_validation(algorithm=hp.linear_regression, formula=model4, data=df, repetitions=5)\n",
    "\n",
    "print('Our 95% credible interval for these 50 values for the error is:\\n\\t {a}'.format(a=stats.mstats.mquantiles(cv_results['sigma_metric'],[0.025, 0.975])))\n",
    "print('Our 95% credible interval for these 50 values for the R^2 is: \\n\\t {a}'.format(a=stats.mstats.mquantiles(cv_results['r2_metric'],[0.025, 0.975])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can the cross-validation results across 50 simulations to see what our credible intervals for both the error and $R^2$ for our final model. While our error is fairly tightly bound, the $R^2$ barely gets into the acceptable range. The heteroscedasticity of the housing permits data is the most likely culprit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Use the Model\n",
    "\n",
    "To recap, our null model predicts we should expect the following housing inventory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = np.mean(df['housing_inventory'])\n",
    "sd = np.std(df['housing_inventory'])\n",
    "\n",
    "print(\"Null model predicts {a} houses\".format(a=round(null, 5)))\n",
    "print(\"With a theoretical 95% error bounds of {a} houses - {b} houses\".format(a = round(null - 1.96 * sd,5), b = round(null + 1.96 * sd, 5 )))\n",
    "print(\"Or a more practical95% error bounds of {a} houses - {b} houses\".format(a = round(0,5), b = round(null + 1.96 * sd, 5 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the linear model we developed to make some predictions.\n",
    "\n",
    "## 4a. Prediction 1\n",
    "\n",
    "First, let's find the predicted housing inventory for 5,000 building permits in a notional location (aka, no particular cbsa location), a mortgage rate of 2.0%, revolving credit of 750,000 millions, and a prime rate of 4.0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sd = result4['sigma']\n",
    "\n",
    "permits, mortgage_interest, revolve_credit_M, prime_interest, = 5000, 0.02, 750000, 0.04\n",
    "query_list = [1, permits, mortgage_interest, revolve_credit_M, prime_interest, mortgage_interest * prime_interest,\n",
    "              mortgage_interest * revolve_credit_M, prime_interest * revolve_credit_M, 0]\n",
    "prediction = result4['model'].predict([query_list])[0][0]\n",
    "\n",
    "print(\"Linear model predicts {} houses\".format(round(prediction, 5)))\n",
    "print(\"With a 95% error bounds of {a} houses - {b} houses\".format(a=round(prediction - 1.96 * sd, 5),\n",
    "                                                                  b=round(prediction + 1.96 * sd, 5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction aligns with intuition as it is well within the bounds of our data range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b Prediction 2\n",
    "\n",
    "Second, let's find the predicted housing inventory if we go beyond the far range of our data with 15,000 building permits, a mortgage rate of 10.0%, 1 billion millions in revolving credit, and a prime-rate of 8.0%. This is way off the charts into extrapolation; so, it will be interesting to see what the predicted housing inventory is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits, mortgage_interest, revolve_credit_M, prime_interest, = 15000, 0.10, 10000000, 0.08\n",
    "query_list = [1, permits, mortgage_interest, revolve_credit_M, prime_interest, mortgage_interest * prime_interest,\n",
    "              mortgage_interest * revolve_credit_M, prime_interest * revolve_credit_M, 0]\n",
    "prediction = result4['model'].predict([query_list])[0][0]\n",
    "\n",
    "print(\"Linear model predicts {} houses\".format(round(prediction, 5)))\n",
    "print(\"With a 95% error bounds of {a} houses - {b} houses\".format(a=round(prediction - 1.96 * sd, 5),\n",
    "                                                                  b=round(prediction + 1.96 * sd, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prediction is not realistic as it illustrates what happens if we extrapolate too far beyond the range of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c Prediction 3\n",
    "\n",
    "Third, let's see what happens if we go to the other extreme and predict the housing inventory with 1 building permit, a mortgage rate of 0.5%, 1 million in revolving credit, and a prime rate of 0% (banks are just literally giving money away)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits, mortgage_interest, revolve_credit_M, prime_interest, = 1, 0.05, 1, 0\n",
    "query_list = [1, permits, mortgage_interest, revolve_credit_M, prime_interest, mortgage_interest * prime_interest,\n",
    "              mortgage_interest * revolve_credit_M, prime_interest * revolve_credit_M, 0]\n",
    "prediction = result4['model'].predict([query_list])[0][0]\n",
    "\n",
    "print(\"Linear model predicts {} houses\".format(round(prediction, 5)))\n",
    "print(\"With a 95% error bounds of {a} houses - {b} houses\".format(a=round(prediction - 1.96 * sd, 5),\n",
    "                                                                  b=round(prediction + 1.96 * sd, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, this estimate is lower than intuitively expected as well off of the highest value in our observed data, 108,702 houses. Perhaps the single building permit dragged things down a bit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4d Prediction 4\n",
    "\n",
    "Fourth, let's try to maximize the situation by bumping up the housing permits a bit by taking the situation in prediction 3 and making the housing permits 5,000 for the month. We would expect this to be pretty close our maximum value observed in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits, mortgage_interest, revolve_credit_M, prime_interest, = 5000, 0.05, 1, 0\n",
    "query_list = [1, permits, mortgage_interest, revolve_credit_M, prime_interest, mortgage_interest * prime_interest,\n",
    "              mortgage_interest * revolve_credit_M, prime_interest * revolve_credit_M, 0]\n",
    "prediction = result4['model'].predict([query_list])[0][0]\n",
    "\n",
    "print(\"Linear model predicts {} houses\".format(round(prediction, 5)))\n",
    "print(\"With a 95% error bounds of {a} houses - {b} houses\".format(a=round(prediction - 1.96 * sd, 5),\n",
    "                                                                  b=round(prediction + 1.96 * sd, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! While rates are unrealistic, we've succeeded in hitting a new high value for the housing inventory for the month, 129,735! The most unrealistic parameters to this scenario, pragmatically, is the prime rate being 0 and the revolving credit being only 1 million. If banks were really extending free money to the customers (like the federal banking system has been doing for central banks since about April 2020 to Dec 2021), folks would likely be running up massive sums of interest free credit debt.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4e Prediction 5\n",
    "\n",
    "For our final prediction, let's revise the situation from prediction 4 to reflect people running up massive debt. So, instead of 1 million of revolving credit, let's make it double the max of our highest observed credit or 1091988*2 = 2,183,976 millions. We would expect this to case the housing inventory to dip substantially over our prediction 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits, mortgage_interest, revolve_credit_M, prime_interest, = 5000, 0.05, 2183976, 0\n",
    "query_list = [1, permits, mortgage_interest, revolve_credit_M, prime_interest, mortgage_interest * prime_interest,\n",
    "              mortgage_interest * revolve_credit_M, prime_interest * revolve_credit_M, 0]\n",
    "prediction = result4['model'].predict([query_list])[0][0]\n",
    "\n",
    "print(\"Linear model predicts {} houses\".format(round(prediction, 5)))\n",
    "print(\"With a 95% error bounds of {a} houses - {b} houses\".format(a=round(prediction - 1.96 * sd, 5),\n",
    "                                                                  b=round(prediction + 1.96 * sd, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that was a greater dip than expected! Deep into the negative territory. Practically, this is impossible; however, it does illustrate how consumer debt can dramatically influence the model. Interestingly, and first glance, the coefficient for credit, $beta_3$ is only -0.11; so, it might not immediately stand out as something that would dramatically influence the housing inventory. However, this value is millions aggregated across all households per month. In the United Sates, this is a massive multiplier; hence, revolving credit has a substantial influence on the overall housing inventory per month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[1] Balaban, J. (2018, August 27). When and How to use Weighted Least Squares (WLS) Models. Medium. Retrieved December 4, 2021, from https://towardsdatascience.com/when-and-how-to-use-weighted-least-squares-wls-models-a68808b1a89d\n",
    "\n",
    "[2]Federal Bank St. Louis. (2021, December 1). FRED Economic Data. FRED Economic Data. Retrieved December 6, 2021, from https://fred.stlouisfed.org/series/FEDFUNDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
